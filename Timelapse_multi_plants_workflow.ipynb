{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b58abf",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing Timelapse Multi-plant trays by PlantCV\n",
    "### Workflow\n",
    "a) Optimize workflow on individual image with debug set to 'print' (or 'plot' if using a Jupyter notebook).\n",
    "\n",
    "b) Run workflow on small test set (ideally that spans time and/or treatments).\n",
    "\n",
    "c) Re-optimize workflows on 'problem images' after manual inspection of test set.\n",
    "\n",
    "d) Deploy optimized workflow over test set using parallelization script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0025e",
   "metadata": {},
   "source": [
    "1) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantcv import plantcv as pcv\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a5b34",
   "metadata": {},
   "source": [
    "2) Define class for set input variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90cd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps doing Parallelization\n",
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"sample_data/VIS_TV_AA0231.png\" # define example image  \n",
    "        #self.image = \"sample_data/sampleData/VIS_TV_AA0000.png\" # Just tray\n",
    "        #self.image = \"sample_data/VIS_TV_AA0423.png\" # define example image \n",
    "        #self.image = \"sample_data/VIS_TV_AA0168.png\" # Night image =black \n",
    "        #self.image = \"sample_data/VIS_TV_AA0679.png\"\n",
    "        self.debug = \"plot\" #three options: none, Print, Plot\n",
    "        self.writeimg= False \n",
    "        self.result = \"multi_plant_results.json\" # save the result in this file\n",
    "        self.outdir = \"./output_images/\" # Store the output directory \n",
    "        self.cropeddir = \"./cropped_images/\"\n",
    "# Initialize options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n",
    "\n",
    "# Increase text size in plots\n",
    "pcv.params.text_size = 4\n",
    "pcv.params.text_thickness = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41069b8b",
   "metadata": {},
   "source": [
    "3) Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d046aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   filename - Image file to be read in \n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "img, path, filename = pcv.readimage(filename=args.image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3685d0",
   "metadata": {},
   "source": [
    "4) Image Normalization (if it is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTest = pcv.white_balance(img, mode='hist', roi=None) #White balancing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b1c21",
   "metadata": {},
   "source": [
    "5) Image Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e00e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the image slightly so the plants line up with \n",
    "# the grid that we'll add in a later step\n",
    "\n",
    "# Inputs:\n",
    "#   img = image object, RGB color space\n",
    "#   rotation_deg = Rotation angle in degrees, can be negative, positive values \n",
    "#                  will move counter-clockwise \n",
    "#   crop = If True then image will be cropped to orginal image dimensions, if False\n",
    "#          the image size will be adjusted to accommodate new image dimensions \n",
    "rotate_img = pcv.transform.rotate(img=img, rotation_deg=1.7, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62947b",
   "metadata": {},
   "source": [
    "6) Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "pcv.params.line_thickness = 1 # Default = 5\n",
    "\n",
    "crop_img = pcv.crop(img=rotate_img, x=14, y=10, h=352, w=205)\n",
    "img1=crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083733c",
   "metadata": {},
   "source": [
    "7) Save croped-rotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3821ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to creat croped_images folder firsr\n",
    "cv2.imwrite(args.cropeddir+filename,img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2bdcf1",
   "metadata": {},
   "source": [
    "8) Apply filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b01f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform erosion filtering\n",
    "# Results in removal of isolated pixels or boundary of object removal\n",
    "er_img = pcv.erode(gray_img=img1, ksize=3, i=1)\n",
    "\n",
    "#Applies a gaussian blur filter. \n",
    "gaussian_img = pcv.gaussian_blur(img=img1, ksize=(3, 3), sigma_x=0, sigma_y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168ba77",
   "metadata": {},
   "source": [
    "9) Visualize Potential Colorspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e05336",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_plot = pcv.visualize.colorspaces(rgb_img=er_img, original_img=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0dd32",
   "metadata": {},
   "source": [
    "10) Convert image from RGB color space to LAB or HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f098ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    rgb_img = image object, RGB color space\n",
    "#    channel = color subchannel ('l' = lightness, 'a' = green-magenta , 'b' = blue-yellow)\n",
    "a = pcv.rgb2gray_lab(rgb_img=er_img, channel='a') # Keep only the green-magenta channel (grayscale)\n",
    "b = pcv.rgb2gray_lab(rgb_img=er_img, channel='b') #'b' = blue-yellow\n",
    "s = pcv.rgb2gray_hsv(rgb_img=er_img, channel='s') # 's' = saturation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87b755",
   "metadata": {},
   "source": [
    "11) Object Segmentation Approaches - thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60726dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a binary threshold on the saturation channel image\n",
    "\n",
    "# Inputs:\n",
    "#    gray_img    = img object, grayscale\n",
    "#    threshold   = threshold value (0-255)\n",
    "#    max_value   = value to apply above threshold (usually 255 = white)\n",
    "#    object_type = light or dark\n",
    "#       - If object is light then standard thresholding is done\n",
    "#       - If object is dark then inverse thresholding is done\n",
    "img_binary_a = pcv.threshold.binary(gray_img=a, threshold=131, max_value=255, object_type='dark') # for a channel\n",
    "\n",
    "img_binary_b = pcv.threshold.binary(gray_img=b, threshold=138, max_value=255, object_type='light') # for b channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113f9eb",
   "metadata": {},
   "source": [
    "12) Combine two images after applying different thresholds (logical_and OR logical_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For logical 'and' operation object pixel must be in both images \n",
    "# to be included in 'and' image.\n",
    "a_b = pcv.logical_and(bin_img1=img_binary_a,bin_img2=img_binary_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a455ded",
   "metadata": {},
   "source": [
    "13) Check if this is a night image or just a tray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48973434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To make sure that images are not taken at night we check that the image isn't mostly dark (0=black, 255=white).\n",
    "# if it is a night image it throws a fatal error and stops the workflow.\n",
    "if np.average(a_b) < 1:\n",
    "    pcv.fatal_error(\"Night Image Or Just a tray!\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e04ce5",
   "metadata": {},
   "source": [
    "14) Noise Reduction -'noise' (non-target-object spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in small objects (speckles)\n",
    "\n",
    "# Inputs:\n",
    "#    bin_img  = binary image. img will be returned after filling\n",
    "#    size     = minimum object area size in pixels (integer)\n",
    "fill_image = pcv.fill(bin_img=a_b, size=2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38283a",
   "metadata": {},
   "source": [
    "15) Dilate so that you don't lose leaves (just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated = pcv.dilate(gray_img=fill_image, ksize=2, i=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c623e",
   "metadata": {},
   "source": [
    "16) Find objects (apply mask for object detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86342826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    img  = image that the objects will be overlayed\n",
    "#    mask = what is used for object detection\n",
    "id_objects, obj_hierarchy = pcv.find_objects(img=img1, mask=dilated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29abeaa9",
   "metadata": {},
   "source": [
    "17) Region of Interest - Keep objects that overlap with the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our case the ROI is the same as whole tray\n",
    "pcv.params.line_thickness = 1# Default = 5\n",
    "\n",
    "# Inputs:\n",
    "#    img            = img to display kept objects\n",
    "#    roi_contour    = contour of roi, output from any ROI function\n",
    "#    roi_hierarchy  = contour of roi, output from any ROI function\n",
    "#    object_contour = contours of objects, output from pcv.find_objects function\n",
    "#    obj_hierarchy  = hierarchy of objects, output from pcv.find_objects function\n",
    "#    roi_type       = 'partial' (default, for partially inside the ROI), 'cutto', or \n",
    "#                     'largest' (keep only largest contour)\n",
    "roi_contour, roi_hierarchy = pcv.roi.rectangle(img=img1, x=5, y=3, h=347, w=200)\n",
    "\n",
    "roi_objects, roi_obj_hierarchy, kept_mask, obj_area = pcv.roi_objects(img=img1, roi_contour=roi_contour, \n",
    "                                                                      roi_hierarchy=roi_hierarchy,\n",
    "                                                                      object_contour=id_objects, \n",
    "                                                                      obj_hierarchy=obj_hierarchy, \n",
    "                                                                      roi_type='partial')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e89063",
   "metadata": {},
   "source": [
    "18- a) Clustering - Based on user input of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv.params.line_thickness = 3 # Default = 5\n",
    "\n",
    "# This function take a image with multiple contours and clusters them based on user input of rows and columns\n",
    "# Inputs:\n",
    "#    img               = An RGB or grayscale image\n",
    "#    roi_objects       = object contours in an image that are needed to be clustered.\n",
    "#    roi_obj_hierarchy = object hierarchy\n",
    "#    nrow              = number of rows to cluster (this should be the approximate  number of \n",
    "#                        desired rows in the entire image even if there isn't a literal row of plants)\n",
    "#    ncol              = number of columns to cluster (this should be the approximate number of \n",
    "#                        desired columns in the entire image even if there isn't a literal row of plants)\n",
    "#    show_grid         = if True then the grid is drawn on the image, default show_grid=False\n",
    "clusters_i, contours, hierarchies = pcv.cluster_contours(img=img1, roi_objects=roi_objects, \n",
    "                                                         roi_obj_hierarchy=roi_obj_hierarchy, \n",
    "                                                         nrow=9, ncol=5, \n",
    "                                                         show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7627f3b",
   "metadata": {},
   "source": [
    "Plot to visualize each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33889487",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv.params.text_size = .4 \n",
    "pcv.params.text_thickness = 1 \n",
    "\n",
    "# Plot to visualize what pieces of plant got grouped together.\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting\n",
    "#   grouped_contour_indices - Indices for grouping contours\n",
    "#   roi_objects - object contours in an image that are needed to be clustered.\n",
    "#   roi_obj_hierarchy - object hierarchy\n",
    "#   nrow - Optional, number of rows. If changed from default, grid gets plot. \n",
    "#   ncol - Optional, number of columns. If changed from default, grid gets plot. \n",
    "cluster_img = pcv.visualize.clustered_contours(img=img1, grouped_contour_indices=clusters_i, \n",
    "                                                roi_objects=contours,\n",
    "                                                roi_obj_hierarchy=hierarchies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca53dd9",
   "metadata": {},
   "source": [
    "18- b) Segment features of images based on their distance to each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "# mask             = Mask/binary image to segment into clusters.\n",
    "# algorithm        = Algorithm to use for segregating different clusters.\n",
    "#                    Currently supporting OPTICS and DBSCAN. (Default=\"DBSCAN\") Density-based spatial clustering of applications with noise (DBSCAN)\n",
    "# min_cluster_size = The minimum size a section of a mask must be (in pixels)\n",
    "#                    before it can be considered its own cluster. (Default=5)\n",
    "# max_distance     = The total distance between two pixels for them to be considered a part\n",
    "#                    of the same cluster.  For the DBSCAN algorithm, value must be between\n",
    "#                    0 and 1.  For OPTICS, the value is in pixels and depends on the size\n",
    "#                    of your picture.  (Default=0)\n",
    "clust_img, clust_masks = pcv.spatial_clustering(mask=kept_mask, algorithm=\"OPTICS\", min_cluster_size=5, max_distance=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218599e",
   "metadata": {},
   "source": [
    "19) Cluster Contours and Split Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes clustered contours and splits them into multiple images,\n",
    "# also does a check to make sure that the number of inputted filenames matches the number\n",
    "# of clustered contours. If no filenames are given then the objects are just numbered\n",
    "\n",
    "# Inputs:\n",
    "#    img                     = ideally a masked RGB image.\n",
    "#    grouped_contour_indexes = output of cluster_contours, indexes of clusters of contours\n",
    "#    contours                = contours to cluster, output of cluster_contours\n",
    "#    hierarchy               = object hierarchy\n",
    "#    outdir                  = directory for output images\n",
    "#    file                    = the name of the input image to use as a base name , output of filename from read_image function\n",
    "#    filenames               = input txt file with list of filenames in order from top to bottom left to right (likely list of genotypes)\n",
    "\n",
    "# Set global debug behavior to None (default), \"print\" (to file), or \"plot\" (Jupyter Notebooks or X11)\n",
    "pcv.params.debug = \"None\"\n",
    "\n",
    "out = args.outdir\n",
    "  \n",
    "output_path = pcv.cluster_contour_splitimg(img=img1, grouped_contour_indexes=clusters_i, contours=contours, \n",
    "                                           hierarchy=hierarchies, outdir=out, file=filename, filenames=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
